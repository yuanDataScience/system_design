{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardinality\n",
    "\n",
    "The values of a categorical variable are selected from a group of categories, also called labels. For example, in the variable _gender_ the categories are male and female, whereas in the variable _city_ the labels could be London, Manchester, Brighton, and so on.\n",
    "\n",
    "Categorical variables can contain different numbers of categories. The variable \"gender\" contains only 2 labels, but a variable like \"city\" or \"postcode\" can contain a huge number of labels.\n",
    "\n",
    "The number of different labels is known as cardinality. A high number of labels within a variable is known as __high cardinality__.\n",
    "\n",
    "\n",
    "## Is high cardinality a problem?\n",
    "\n",
    "High cardinality poses the following challenges:Â \n",
    "\n",
    "- Variables with too many labels tend to dominate those with only a few labels, particularly in **decision tree-based** algorithms.\n",
    "\n",
    "- High cardinality may introduce noise.\n",
    "\n",
    "- Some of the labels may only be present in the training data set and not in the test set, so machine learning algorithms may over-fit to the training set.\n",
    "\n",
    "- Some labels may appear only in the test set, leaving the machine learning algorithms unable to perform a calculation over the new (unseen) observation.\n",
    "\n",
    "**Algorithms based on decision trees can be biased towards variables with high cardinality**.\n",
    "\n",
    "Below is a demo about the effect of high cardinality on the performance of various machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this Demo:\n",
    "\n",
    "- Learn how to quantify cardinality.\n",
    "- See examples of high and low cardinality variables.\n",
    "- Understand the effect of cardinality in train and test sets.\n",
    "- Evaluate the effect of cardinality on machine learning model performance.\n",
    "\n",
    "We will use the Titanic dataset.\n",
    "\n",
    "- To download the dataset, please refer to the **Datasets** lecture in **Section 2** of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The machine learning models.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# To evaluate the models.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# To separate data into train and test.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375    B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500   C22        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500   C22        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500   C22        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500   C22        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's load the titanic dataset.\n",
    "\n",
    "data = pd.read_csv('../titanic.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical variables are Name, Sex, Ticket, Cabin and Embarked.\n",
    "\n",
    "**Note** that Ticket and Cabin contain both letters and numbers, so they could be treated as Mixed Variables. In this demo, I will treat them as categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories in the variable Name: 1307\n",
      "Number of categories in the variable Gender: 2\n",
      "Number of categories in the variable Ticket: 929\n",
      "Number of categories in the variable Cabin: 182\n",
      "Number of categories in the variable Embarked: 4\n",
      "Total number of passengers in the Titanic: 1309\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect the cardinality: the number\n",
    "# of different labels.\n",
    "\n",
    "print('Number of categories in the variable Name: {}'.format(\n",
    "    len(data.name.unique())))\n",
    "\n",
    "print('Number of categories in the variable Gender: {}'.format(\n",
    "    len(data.sex.unique())))\n",
    "\n",
    "print('Number of categories in the variable Ticket: {}'.format(\n",
    "    len(data.ticket.unique())))\n",
    "\n",
    "print('Number of categories in the variable Cabin: {}'.format(\n",
    "    len(data.cabin.unique())))\n",
    "\n",
    "print('Number of categories in the variable Embarked: {}'.format(\n",
    "    len(data.embarked.unique())))\n",
    "\n",
    "print('Total number of passengers in the Titanic: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the variable Sex contains only 2 categories and the variable Embarked 4 (low cardinality), the variables Ticket, Name, and Cabin, as expected, contain a huge number of different labels (high cardinality).\n",
    "\n",
    "To demonstrate the effect of high cardinality on train and test sets and on machine learning performance, I will work with the variable cabin. I will create a new variable with reduced cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B5', 'C22', 'E12', 'D7', 'A36', 'C101', nan, 'C62', 'B35', 'A23',\n",
       "       'B58', 'D15', 'C6', 'D35', 'C148', 'C97', 'B49', 'C99', 'C52', 'T',\n",
       "       'A31', 'C7', 'C103', 'D22', 'E33', 'A21', 'B10', 'B4', 'E40',\n",
       "       'B38', 'E24', 'B51', 'B96', 'C46', 'E31', 'E8', 'B61', 'B77', 'A9',\n",
       "       'C89', 'A14', 'E58', 'E49', 'E52', 'E45', 'B22', 'B26', 'C85',\n",
       "       'E17', 'B71', 'B20', 'A34', 'C86', 'A16', 'A20', 'A18', 'C54',\n",
       "       'C45', 'D20', 'A29', 'C95', 'E25', 'C111', 'C23', 'E36', 'D34',\n",
       "       'D40', 'B39', 'B41', 'B102', 'C123', 'E63', 'C130', 'B86', 'C92',\n",
       "       'A5', 'C51', 'B42', 'C91', 'C125', 'D10', 'B82', 'E50', 'D33',\n",
       "       'C83', 'B94', 'D49', 'D45', 'B69', 'B11', 'E46', 'C39', 'B18',\n",
       "       'D11', 'C93', 'B28', 'C49', 'B52', 'E60', 'C132', 'B37', 'D21',\n",
       "       'D19', 'C124', 'D17', 'B101', 'D28', 'D6', 'D9', 'B80', 'C106',\n",
       "       'B79', 'C47', 'D30', 'C90', 'E38', 'C78', 'C30', 'C118', 'D36',\n",
       "       'D48', 'D47', 'C105', 'B36', 'B30', 'D43', 'B24', 'C2', 'C65',\n",
       "       'B73', 'C104', 'C110', 'C50', 'B3', 'A24', 'A32', 'A11', 'A10',\n",
       "       'B57', 'C28', 'E44', 'A26', 'A6', 'A7', 'C31', 'A19', 'B45', 'E34',\n",
       "       'B78', 'B50', 'C87', 'C116', 'C55', 'D50', 'E68', 'E67', 'C126',\n",
       "       'C68', 'C70', 'C53', 'B19', 'D46', 'D37', 'D26', 'C32', 'C80',\n",
       "       'C82', 'C128', 'E39', 'D', 'F4', 'D56', 'F33', 'E101', 'E77', 'F2',\n",
       "       'D38', 'F', 'E121', 'E10', 'G6', 'F38'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore the values of Cabin.\n",
    "\n",
    "# We know from the previous cell that there are 148\n",
    "# different cabins, therefore the variable\n",
    "# is highly cardinal.\n",
    "\n",
    "data.cabin.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reduce the cardinality of the variable. How? Instead of using the entire value (letter + number), I will only use the first letter.\n",
    "\n",
    "***Rationale***: the first letter indicates the deck on which the cabin was located, indicating both social class status and proximity to the Titanic's surface. Both are known to improve the probability of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cabin</th>\n",
       "      <th>Cabin_reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B5</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C22</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C22</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C22</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C22</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cabin Cabin_reduced\n",
       "0    B5             B\n",
       "1   C22             C\n",
       "2   C22             C\n",
       "3   C22             C\n",
       "4   C22             C"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's capture the first letter of cabin.\n",
    "\n",
    "data['Cabin_reduced'] = data['cabin'].astype(str).str[0]\n",
    "\n",
    "data[['cabin', 'Cabin_reduced']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories in the variable Cabin: 182\n",
      "Number of categories in the variable Cabin reduced: 9\n"
     ]
    }
   ],
   "source": [
    "print('Number of categories in the variable Cabin: {}'.format(\n",
    "    len(data.cabin.unique())))\n",
    "\n",
    "print('Number of categories in the variable Cabin reduced: {}'.format(\n",
    "    len(data.Cabin_reduced.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reduced the number of different labels from 182 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((916, 3), (393, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's separate the data into training and testing sets.\n",
    "\n",
    "use_cols = ['cabin', 'Cabin_reduced', 'sex']\n",
    "\n",
    "# This functions is from Scikit-learn\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[use_cols], \n",
    "    data['survived'],  \n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uneven distribution of categories\n",
    "\n",
    "When a variable is highly cardinal, some categories appear only on the training set, and others only on the testing set. If present only in the training set, they may cause over-fitting. If present only on the testing set, the machine learning model will not know how to handle them, as they were not seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels present only in the training set:\n",
    "\n",
    "unique_to_train_set = [\n",
    "    x for x in X_train.cabin.unique() if x not in X_test.cabin.unique()\n",
    "]\n",
    "\n",
    "len(unique_to_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 113 Cabins only present in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels present only in the test set.\n",
    "\n",
    "unique_to_test_set = [\n",
    "    x for x in X_test.cabin.unique() if x not in X_train.cabin.unique()\n",
    "]\n",
    "\n",
    "len(unique_to_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables with high cardinality have categories present either only in the training set, or only in the testing set. This will cause problems at the time of training (over-fitting) and scoring of new data (how will the model deal with unseen categories?).\n",
    "\n",
    "This problem can be mitigated by reducing the cardinality of the variable. Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels present only in the training set\n",
    "# for Cabin with reduced cardinality.\n",
    "\n",
    "unique_to_train_set = [\n",
    "    x for x in X_train['Cabin_reduced'].unique()\n",
    "    if x not in X_test['Cabin_reduced'].unique()\n",
    "]\n",
    "\n",
    "len(unique_to_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels present only in the test set\n",
    "# for Cabin with reduced cardinality.\n",
    "\n",
    "unique_to_test_set = [\n",
    "    x for x in X_test['Cabin_reduced'].unique()\n",
    "    if x not in X_train['Cabin_reduced'].unique()\n",
    "]\n",
    "\n",
    "len(unique_to_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reducing the cardinality, there is now only 1 label in the training set that is not present in the test set. There is no label in the test set that is not in the training set either.\n",
    "\n",
    "## The impact of cardinality on the performance of machine learning models\n",
    "\n",
    "In order to evaluate the effect of categorical variables in machine learning models, I will quickly replace the categories with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: 0,\n",
       " 'E36': 1,\n",
       " 'C68': 2,\n",
       " 'E24': 3,\n",
       " 'C22': 4,\n",
       " 'D38': 5,\n",
       " 'B50': 6,\n",
       " 'A24': 7,\n",
       " 'C111': 8,\n",
       " 'F': 9,\n",
       " 'C6': 10,\n",
       " 'C87': 11,\n",
       " 'E8': 12,\n",
       " 'B45': 13,\n",
       " 'C93': 14,\n",
       " 'D28': 15,\n",
       " 'D36': 16,\n",
       " 'C125': 17,\n",
       " 'B35': 18,\n",
       " 'T': 19,\n",
       " 'B73': 20,\n",
       " 'B57': 21,\n",
       " 'A26': 22,\n",
       " 'A18': 23,\n",
       " 'B96': 24,\n",
       " 'G6': 25,\n",
       " 'C78': 26,\n",
       " 'C101': 27,\n",
       " 'D9': 28,\n",
       " 'D33': 29,\n",
       " 'C128': 30,\n",
       " 'E50': 31,\n",
       " 'B26': 32,\n",
       " 'B69': 33,\n",
       " 'E121': 34,\n",
       " 'C123': 35,\n",
       " 'B94': 36,\n",
       " 'A34': 37,\n",
       " 'D': 38,\n",
       " 'C39': 39,\n",
       " 'D43': 40,\n",
       " 'E31': 41,\n",
       " 'B5': 42,\n",
       " 'D17': 43,\n",
       " 'F33': 44,\n",
       " 'E44': 45,\n",
       " 'D7': 46,\n",
       " 'A21': 47,\n",
       " 'D34': 48,\n",
       " 'A29': 49,\n",
       " 'D35': 50,\n",
       " 'A11': 51,\n",
       " 'B51': 52,\n",
       " 'D46': 53,\n",
       " 'E60': 54,\n",
       " 'C30': 55,\n",
       " 'D26': 56,\n",
       " 'E68': 57,\n",
       " 'A9': 58,\n",
       " 'B71': 59,\n",
       " 'D37': 60,\n",
       " 'F2': 61,\n",
       " 'C55': 62,\n",
       " 'C89': 63,\n",
       " 'C124': 64,\n",
       " 'C23': 65,\n",
       " 'C126': 66,\n",
       " 'E49': 67,\n",
       " 'E46': 68,\n",
       " 'D19': 69,\n",
       " 'B58': 70,\n",
       " 'C82': 71,\n",
       " 'B52': 72,\n",
       " 'C92': 73,\n",
       " 'E45': 74,\n",
       " 'C65': 75,\n",
       " 'E25': 76,\n",
       " 'B3': 77,\n",
       " 'D40': 78,\n",
       " 'C91': 79,\n",
       " 'B102': 80,\n",
       " 'B61': 81,\n",
       " 'A20': 82,\n",
       " 'B36': 83,\n",
       " 'C7': 84,\n",
       " 'B77': 85,\n",
       " 'D20': 86,\n",
       " 'C148': 87,\n",
       " 'C105': 88,\n",
       " 'E38': 89,\n",
       " 'B86': 90,\n",
       " 'C132': 91,\n",
       " 'C86': 92,\n",
       " 'A14': 93,\n",
       " 'C54': 94,\n",
       " 'A5': 95,\n",
       " 'B49': 96,\n",
       " 'B28': 97,\n",
       " 'B24': 98,\n",
       " 'C2': 99,\n",
       " 'F4': 100,\n",
       " 'A6': 101,\n",
       " 'C83': 102,\n",
       " 'B42': 103,\n",
       " 'A36': 104,\n",
       " 'C52': 105,\n",
       " 'D56': 106,\n",
       " 'C116': 107,\n",
       " 'B19': 108,\n",
       " 'E77': 109,\n",
       " 'E101': 110,\n",
       " 'B18': 111,\n",
       " 'C95': 112,\n",
       " 'D15': 113,\n",
       " 'E33': 114,\n",
       " 'B30': 115,\n",
       " 'D21': 116,\n",
       " 'E10': 117,\n",
       " 'C130': 118,\n",
       " 'D6': 119,\n",
       " 'C51': 120,\n",
       " 'D30': 121,\n",
       " 'E67': 122,\n",
       " 'C110': 123,\n",
       " 'C103': 124,\n",
       " 'C90': 125,\n",
       " 'C118': 126,\n",
       " 'C97': 127,\n",
       " 'D47': 128,\n",
       " 'E34': 129,\n",
       " 'B4': 130,\n",
       " 'D50': 131,\n",
       " 'C62': 132,\n",
       " 'E17': 133,\n",
       " 'B41': 134,\n",
       " 'C49': 135,\n",
       " 'C85': 136,\n",
       " 'B20': 137,\n",
       " 'C28': 138,\n",
       " 'E63': 139,\n",
       " 'C99': 140,\n",
       " 'D49': 141,\n",
       " 'A10': 142,\n",
       " 'A16': 143,\n",
       " 'B37': 144,\n",
       " 'C80': 145,\n",
       " 'B78': 146}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's re-map Cabin into numbers so we can use it to train ML models\n",
    "\n",
    "# I will replace each cabin by a number\n",
    "# to quickly demonstrate the effect of\n",
    "# labels on machine learning algorithms.\n",
    "\n",
    "##############\n",
    "# Note: this is neither the only nor the best\n",
    "# way to encode categorical variables into numbers.\n",
    "# There is more on encoding techniques in the section\n",
    "# \"Encoding categorical variales\".\n",
    "##############\n",
    "\n",
    "cabin_dict = {k: i for i, k in enumerate(X_train.cabin.unique(), 0)}\n",
    "cabin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin_mapped</th>\n",
       "      <th>cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "      <td>E36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2</td>\n",
       "      <td>C68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>3</td>\n",
       "      <td>E24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cabin_mapped cabin\n",
       "501              0   NaN\n",
       "588              0   NaN\n",
       "402              0   NaN\n",
       "1193             0   NaN\n",
       "686              0   NaN\n",
       "971              0   NaN\n",
       "117              1   E36\n",
       "540              0   NaN\n",
       "294              2   C68\n",
       "261              3   E24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the labels in Cabin with the dictionary\n",
    "# we just created.\n",
    "\n",
    "X_train.loc[:, 'Cabin_mapped'] = X_train.loc[:, 'cabin'].map(cabin_dict)\n",
    "X_test.loc[:, 'Cabin_mapped'] = X_test.loc[:, 'cabin'].map(cabin_dict)\n",
    "\n",
    "X_train[['Cabin_mapped', 'cabin']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how NaN takes the value 0, E36 takes the value 1, C68 takes the value 2, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sole\\AppData\\Local\\Temp\\ipykernel_9944\\4185337699.py:8: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_train.loc[:, 'Cabin_reduced'] = X_train.loc[:, 'Cabin_reduced'].map(\n",
      "C:\\Users\\Sole\\AppData\\Local\\Temp\\ipykernel_9944\\4185337699.py:10: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_test.loc[:, 'Cabin_reduced'] = X_test.loc[:, 'Cabin_reduced'].map(cabin_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin_reduced</th>\n",
       "      <th>cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "      <td>E36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2</td>\n",
       "      <td>C68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>E24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cabin_reduced cabin\n",
       "501               0   NaN\n",
       "588               0   NaN\n",
       "402               0   NaN\n",
       "1193              0   NaN\n",
       "686               0   NaN\n",
       "971               0   NaN\n",
       "117               1   E36\n",
       "540               0   NaN\n",
       "294               2   C68\n",
       "261               1   E24\n",
       "587               0   NaN\n",
       "489               0   NaN\n",
       "2                 2   C22\n",
       "405               0   NaN\n",
       "1284              0   NaN\n",
       "338               0   NaN\n",
       "356               0   NaN\n",
       "985               0   NaN\n",
       "182               0   NaN\n",
       "1027              0   NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I will replace the letters in the reduced cabin variable\n",
    "# using the same procedure.\n",
    "\n",
    "# Create replacement dictionary.\n",
    "cabin_dict = {k: i for i, k in enumerate(X_train['Cabin_reduced'].unique(), 0)}\n",
    "\n",
    "# Replace labels by numbers using dictionary.\n",
    "X_train.loc[:, 'Cabin_reduced'] = X_train.loc[:, 'Cabin_reduced'].map(\n",
    "    cabin_dict)\n",
    "X_test.loc[:, 'Cabin_reduced'] = X_test.loc[:, 'Cabin_reduced'].map(cabin_dict)\n",
    "\n",
    "X_train[['Cabin_reduced', 'cabin']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now that E36 and E24 take the same number, 1, because we are capturing only the letter. They both start with E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sole\\AppData\\Local\\Temp\\ipykernel_9944\\3967386210.py:3: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_train.loc[:, 'sex'] = X_train.loc[:, 'sex'].map({'male': 0, 'female': 1})\n",
      "C:\\Users\\Sole\\AppData\\Local\\Temp\\ipykernel_9944\\3967386210.py:4: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_test.loc[:, 'sex'] = X_test.loc[:, 'sex'].map({'male': 0, 'female': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "501     1\n",
       "588     1\n",
       "402     1\n",
       "1193    0\n",
       "686     1\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-map the categorical variable Sex into numbers.\n",
    "\n",
    "X_train.loc[:, 'sex'] = X_train.loc[:, 'sex'].map({'male': 0, 'female': 1})\n",
    "X_test.loc[:, 'sex'] = X_test.loc[:, 'sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "X_train.sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_mapped     0\n",
       "Cabin_reduced    0\n",
       "sex              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are missing values in these variables.\n",
    "\n",
    "X_train[['Cabin_mapped', 'Cabin_reduced', 'sex']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_mapped     41\n",
       "Cabin_reduced     0\n",
       "sex               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[['Cabin_mapped', 'Cabin_reduced', 'sex']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test set, there are now 41 missing values for the highly cardinal variable. These were introduced when encoding the categories into numbers. \n",
    "\n",
    "How? \n",
    "\n",
    "Many categories exist only in the test set. Thus, when we created our encoding dictionary using only the train set, we did not generate a number to replace those labels present only in the test set. As a consequence, they were encoded as NaN. We will see in future notebooks how to tackle this problem. For now, I will fill in those missing values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the number of different \n",
    "# categories in the encoded variables.\n",
    "\n",
    "len(X_train.Cabin_mapped.unique()), len(X_train.Cabin_reduced.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we note immediately that from the original 182 cabins in the dataset, only 147 are present in the training set. We also see how we reduced the number of different categories to just 9 in our previous step.\n",
    "\n",
    "Let's go ahead and evaluate the effect of cardinality in machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.853790650048556\n",
      "Test set\n",
      "Random Forests roc-auc: 0.7691361097284443\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with high cardinality.\n",
    "\n",
    "# The model.\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39)\n",
    "\n",
    "# Train the model.\n",
    "rf.fit(X_train[['Cabin_mapped', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set.\n",
    "pred_train = rf.predict_proba(X_train[['Cabin_mapped', 'sex']])\n",
    "pred_test = rf.predict_proba(X_test[['Cabin_mapped', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the Random Forests on the training set is quite superior to its performance on the test set. This indicates that the model is over-fitting, which means that it does a great job of predicting the outcome on the dataset it was trained on, but it lacks the power to generalise the prediction to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8163420365403872\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8017670482827277\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with low cardinality.\n",
    "\n",
    "# The model.\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39)\n",
    "\n",
    "# Train the model.\n",
    "rf.fit(X_train[['Cabin_reduced', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set.\n",
    "pred_train = rf.predict_proba(X_train[['Cabin_reduced', 'sex']])\n",
    "pred_test = rf.predict_proba(X_test[['Cabin_reduced', 'sex']])\n",
    "\n",
    "print('Train set')\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Random Forests no longer over-fit to the training set. The model is much better at generalising the predictions (compare the ROC-AUC of this model vs the ROC-AUC of the previous model: : 0.81 vs 0.80).\n",
    "\n",
    "**I would like to point out, that likely we can overcome the effect of high cardinality by adjusting the hyper-parameters of the random forests. That goes beyond the scope of this course. Here, I want to show you that given a model with identical hyper-parameters, high cardinality may cause the model to over-fit**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Adaboost roc-auc: 0.8296861713101102\n",
      "Test set\n",
      "Adaboost roc-auc: 0.7604391350035948\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with high cardinality.\n",
    "\n",
    "# The model.\n",
    "ada = AdaBoostClassifier(n_estimators=200, random_state=44)\n",
    "\n",
    "# Train the model.\n",
    "ada.fit(X_train[['Cabin_mapped', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set\n",
    "pred_train = ada.predict_proba(X_train[['Cabin_mapped', 'sex']])\n",
    "pred_test = ada.predict_proba(X_test[['Cabin_mapped', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('AdaBoost roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('AdaBoost roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Adaboost roc-auc: 0.8161256723642566\n",
      "Test set\n",
      "Adaboost roc-auc: 0.8001078480172557\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with fewer categories.\n",
    "\n",
    "# The model.\n",
    "ada = AdaBoostClassifier(n_estimators=200, random_state=44)\n",
    "\n",
    "# Train the model.\n",
    "ada.fit(X_train[['Cabin_reduced', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set.\n",
    "pred_train = ada.predict_proba(X_train[['Cabin_reduced', 'sex']])\n",
    "pred_test = ada.predict_proba(X_test[['Cabin_reduced', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('AdaBoost roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('AdaBoost roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Similarly, Adaboost trained with the variable with high cardinality overfits to the train set. Adaboost trained with the low cardinal variable does not overfit.\n",
    "\n",
    "In addition, training AdaBoost with data with less categories in Cabin, returns a) a simpler model and, b) should a different category in the test set appear, by taking just the front letter of cabin, the ML model will know how to handle it because, most likely, the value was seen during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic regression roc-auc: 0.8133909298124677\n",
      "Test set\n",
      "Logistic regression roc-auc: 0.7750815773463858\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with high cardinality.\n",
    "\n",
    "# The model.\n",
    "logit = LogisticRegression(random_state=44, solver='lbfgs')\n",
    "\n",
    "# Train the model.\n",
    "logit.fit(X_train[['Cabin_mapped', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set.\n",
    "pred_train = logit.predict_proba(X_train[['Cabin_mapped', 'sex']])\n",
    "pred_test = logit.predict_proba(X_test[['Cabin_mapped', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('Logistic regression roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Logistic regression roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic regression roc-auc: 0.8123468468695123\n",
      "Test set\n",
      "Logistic regression roc-auc: 0.8008268347989602\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with fewer categories.\n",
    "\n",
    "# The model.\n",
    "logit = LogisticRegression(random_state=44, solver='lbfgs')\n",
    "\n",
    "# Train the model.\n",
    "logit.fit(X_train[['Cabin_reduced', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set.\n",
    "pred_train = logit.predict_proba(X_train[['Cabin_reduced', 'sex']])\n",
    "pred_test = logit.predict_proba(X_test[['Cabin_reduced', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('Logistic regression roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Logistic regression roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw the same conclusions for Logistic Regression: reducing the cardinality improves the performance of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Gradient Boosted Trees roc-auc: 0.862631390919749\n",
      "Test set\n",
      "Gradient Boosted Trees roc-auc: 0.7733117637298823\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with high cardinality.\n",
    "\n",
    "# The model.\n",
    "gbc = GradientBoostingClassifier(n_estimators=300, random_state=44)\n",
    "\n",
    "# Train the model.\n",
    "gbc.fit(X_train[['Cabin_mapped', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set\n",
    "pred_train = gbc.predict_proba(X_train[['Cabin_mapped', 'sex']])\n",
    "pred_test = gbc.predict_proba(X_test[['Cabin_mapped', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('Gradient Boosted Trees roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Gradient Boosted Trees roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Gradient Boosted Trees roc-auc: 0.816719415917359\n",
      "Test set\n",
      "Gradient Boosted Trees roc-auc: 0.8015181682429069\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with fewer categories.\n",
    "\n",
    "# call the model\n",
    "gbc = GradientBoostingClassifier(n_estimators=300, random_state=44)\n",
    "\n",
    "# train the model\n",
    "gbc.fit(X_train[['Cabin_reduced', 'sex']], y_train)\n",
    "\n",
    "# make predictions on train and test set\n",
    "pred_train = gbc.predict_proba(X_train[['Cabin_reduced', 'sex']])\n",
    "pred_test = gbc.predict_proba(X_test[['Cabin_reduced', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('Gradient Boosted Trees roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Gradient Boosted Trees roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosted trees are overfit to the training set when using a variable with high cardinality. This was expected as tree-based methods tend to be biased to variables with plenty of categories.\n",
    "\n",
    "**That is all for this demonstration. I hope you enjoyed the notebook, and I'll see you in the next one.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsml",
   "language": "python",
   "name": "fsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
